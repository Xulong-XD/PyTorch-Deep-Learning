{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8a927c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d7c328e",
   "metadata": {},
   "source": [
    "# 3.1 张量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fa86e249",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.2000)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 标量\n",
    "a = torch.tensor(1.2)\n",
    "a "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "452a875f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11.])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 向量\n",
    "x = torch.arange(12, dtype=torch.float32)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0cc4c9b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  1,  2,  3],\n",
       "        [ 4,  5,  6,  7],\n",
       "        [ 8,  9, 10, 11]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 矩阵\n",
    "X = torch.arange(12).reshape((3, 4))\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b585281f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.,  1.,  2.,  3.],\n",
       "         [ 4.,  5.,  6.,  7.],\n",
       "         [ 8.,  9., 10., 11.]],\n",
       "\n",
       "        [[12., 13., 14., 15.],\n",
       "         [16., 17., 18., 19.],\n",
       "         [20., 21., 22., 23.]]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 三阶张量\n",
    "X = torch.arange(24, dtype=torch.float32).reshape((2, 3, 4))\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8cae9c7",
   "metadata": {},
   "source": [
    "# 3.2 张量运算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "9b38e236",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0.,  1.,  2.,  3.],\n",
       "         [ 4.,  5.,  6.,  7.],\n",
       "         [ 8.,  9., 10., 11.]]),\n",
       " tensor([[ 0.,  2.,  4.,  6.],\n",
       "         [ 8., 10., 12., 14.],\n",
       "         [16., 18., 20., 22.]]),\n",
       " tensor([[  0.,   2.,   8.,  18.],\n",
       "         [ 32.,  50.,  72.,  98.],\n",
       "         [128., 162., 200., 242.]]),\n",
       " tensor([[ 2.,  3.,  4.,  5.],\n",
       "         [ 6.,  7.,  8.,  9.],\n",
       "         [10., 11., 12., 13.]]),\n",
       " tensor([[ 0.,  4.,  8.],\n",
       "         [ 1.,  5.,  9.],\n",
       "         [ 2.,  6., 10.],\n",
       "         [ 3.,  7., 11.]]))"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.arange(12, dtype=torch.float32).reshape((3, 4))\n",
    "Y = X.clone()\n",
    "a = 2\n",
    "X, X + Y, X * (X + Y), X + a, X.T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50c41ea7",
   "metadata": {},
   "source": [
    "# 3.3 张量降维"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2b4434ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.,  1.,  2.,  3.],\n",
       "        [ 4.,  5.,  6.,  7.],\n",
       "        [ 8.,  9., 10., 11.]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sum(), mean()\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c3cf6dd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(66.)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c0b44469",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([12., 15., 18., 21.])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "59318e16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 6., 22., 38.])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5053d0c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4., 5., 6., 7.])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4f88dc1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.5000, 5.5000, 9.5000])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6aa42555",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 元素个数：numel\n",
    "X.numel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "bd7770a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(5.5000)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.sum() / X.numel()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cef7da29",
   "metadata": {},
   "source": [
    "# 3.4 非降维求和\n",
    "但是，有时在调⽤函数来计算总和或均值时保持轴数不变会很有⽤,例如，由于sum_A在对每⾏进⾏求和后仍保持两个轴，我们可以通过⼴播将A除以sum_A。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "7260652d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.,  1.,  2.,  3.],\n",
       "        [ 4.,  5.,  6.,  7.],\n",
       "        [ 8.,  9., 10., 11.]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "32b08620",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 6.],\n",
       "        [22.],\n",
       "        [38.]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.sum(axis=1, keepdims=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "6b69042e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000, 0.0152, 0.0303, 0.0455],\n",
       "        [0.0606, 0.0758, 0.0909, 0.1061],\n",
       "        [0.1212, 0.1364, 0.1515, 0.1667]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X / X.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00955f04",
   "metadata": {},
   "source": [
    "如果我们想沿某个轴计算A元素的累积总和，⽐如axis=0（按⾏计算），我们可以调⽤cumsum函数。此函数\n",
    "不会沿任何轴降低输⼊张量的维度。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "781be451",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.,  1.,  2.,  3.],\n",
       "        [ 4.,  6.,  8., 10.],\n",
       "        [12., 15., 18., 21.]])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.cumsum(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b16083c7",
   "metadata": {},
   "source": [
    "# 3.5 点积 （Dot Product）\n",
    "我们已经学习了按元素操作、求和及平均值。另⼀个最基本的操作之⼀是点积：给定两个向量$\\mathbf{x},\\mathbf{y}\\in\\mathbb{R}^d$，\n",
    "它们的*点积*（dot product）$\\mathbf{x}^\\top\\mathbf{y}$\n",
    "（或$\\langle\\mathbf{x},\\mathbf{y}\\rangle$）\n",
    "是相同位置的按元素乘积的和：$\\mathbf{x}^\\top \\mathbf{y} = \\sum_{i=1}^{d} x_i y_i$。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "18113804",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1., 2., 3., 4.]), tensor([1., 1., 1., 1.]), tensor(10.))"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor([1, 2, 3, 4], dtype=torch.float32)\n",
    "y = torch.ones(4, dtype=torch.float32)\n",
    "x, y, torch.dot(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c2f6c35",
   "metadata": {},
   "source": [
    "注意，(**我们可以通过执行按元素乘法，然后进行求和来表示两个向量的点积**)：\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e57940e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(10.), tensor(10.))"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(x * y).sum(), torch.sum(x * y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "224642fd",
   "metadata": {},
   "source": [
    "# 3.6矩阵-向量积\n",
    "义的矩阵$\\mathbf{A} \\in \\mathbb{R}^{m \\times n}$和向量$\\mathbf{x} \\in \\mathbb{R}^n$。\n",
    "让我们将矩阵$\\mathbf{A}$用它的行向量表示：\n",
    "\n",
    "$$\\mathbf{A}=\n",
    "\\begin{bmatrix}\n",
    "\\mathbf{a}^\\top_{1} \\\\\n",
    "\\mathbf{a}^\\top_{2} \\\\\n",
    "\\vdots \\\\\n",
    "\\mathbf{a}^\\top_m \\\\\n",
    "\\end{bmatrix},$$\n",
    "\n",
    "其中每个$\\mathbf{a}^\\top_{i} \\in \\mathbb{R}^n$都是行向量，表示矩阵的第$i$行。\n",
    "[**矩阵向量积$\\mathbf{A}\\mathbf{x}$是一个长度为$m$的列向量，\n",
    "其第$i$个元素是点积$\\mathbf{a}^\\top_i \\mathbf{x}$**]：\n",
    "\n",
    "$$\n",
    "\\mathbf{A}\\mathbf{x}\n",
    "= \\begin{bmatrix}\n",
    "\\mathbf{a}^\\top_{1} \\\\\n",
    "\\mathbf{a}^\\top_{2} \\\\\n",
    "\\vdots \\\\\n",
    "\\mathbf{a}^\\top_m \\\\\n",
    "\\end{bmatrix}\\mathbf{x}\n",
    "= \\begin{bmatrix}\n",
    " \\mathbf{a}^\\top_{1} \\mathbf{x}  \\\\\n",
    " \\mathbf{a}^\\top_{2} \\mathbf{x} \\\\\n",
    "\\vdots\\\\\n",
    " \\mathbf{a}^\\top_{m} \\mathbf{x}\\\\\n",
    "\\end{bmatrix}.\n",
    "$$\n",
    "\n",
    "当我们为矩阵`A`和向量`x`调用`torch.mv(A, x)`时，会执行矩阵-向量积。\n",
    "注意，`A`的列维数（沿轴1的长度）必须与`x`的维数（其长度）相同。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "4007258d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0.,  1.,  2.,  3.],\n",
       "         [ 4.,  5.,  6.,  7.],\n",
       "         [ 8.,  9., 10., 11.]]),\n",
       " tensor([0., 1., 2., 3.]),\n",
       " tensor([14., 38., 62.]))"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = torch.arange(12, dtype=torch.float32).reshape(3, 4)\n",
    "x = torch.arange(4, dtype=torch.float32)\n",
    "A, x, torch.mv(A, x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "627a9c5f",
   "metadata": {},
   "source": [
    "# 3.7 矩阵乘法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "32cb3bcb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 42.,  48.,  54.],\n",
       "        [114., 136., 158.],\n",
       "        [186., 224., 262.]])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = torch.arange(12, dtype=torch.float32).reshape(3, 4)\n",
    "B = torch.arange(12, dtype=torch.float32).reshape(4, 3)\n",
    "torch.mm(A, B)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b6eea8a",
   "metadata": {},
   "source": [
    "# 3.8 范数\n",
    "\n",
    "$L_2$范数:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "7395dfa8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 1., 2., 3.])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "0364b159",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.7417)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.norm(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e82bda54",
   "metadata": {},
   "source": [
    "$L_1$范数："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "ca81c7e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(6.)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.abs(x).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edccaaa0",
   "metadata": {},
   "source": [
    "矩阵富比尼范数（矩阵元素平方和的平方根）："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "adfc2edb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(22.4944)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.arange(12, dtype=torch.float32).reshape(3,4)\n",
    "torch.norm(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b866ed3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
