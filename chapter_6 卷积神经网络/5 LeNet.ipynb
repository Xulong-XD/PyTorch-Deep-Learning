{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4cedd1b1",
   "metadata": {},
   "source": [
    "# LeNet\n",
    "在线性神经网络模型中，我们将图像展成一维向量后经过全连接层处理，现在我们可以使用卷积层来处理图像数据，以此保留图像的空间结构。\n",
    "\n",
    "在本节中，我们介绍LeNet，它是最早发布的卷积神经网络之一，因其在计算机视觉任务中的高效性能而受到广泛关注。这个模型是由AT&T贝尔实验室的研究员Yann LeCun在1989年提出的（并以其命名），目的是识别图像 中的手写数字。当时，LeNet取得了与支持向量机（support vector machines）性能相媲美的成果，成为监督学习的主流方法。\n",
    "LeNet被广泛用于自动取款机（ATM）机中，帮助识别处理支票的数字。\n",
    "时至今日，一些自动取款机仍在运行Yann LeCun和他的同事Leon Bottou在上世纪90年代写的代码。\n",
    "\n",
    "## LeNet网络结构\n",
    "总体来看，(**LeNet（LeNet-5）由两个部分组成：**)\n",
    "* 卷积编码器：由两个卷积层组成;\n",
    "* 全连接层密集块：由三个全连接层组成。\n",
    "\n",
    "该架构如 :numref:`img_lenet`所示。\n",
    "![LeNet中的数据流。输入是手写数字，输出为10种可能结果的概率。](./lenet.svg)\n",
    ":label:`img_lenet`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1263b5a2",
   "metadata": {},
   "source": [
    "* 每个卷积块中的基本单元是一个卷积层、一个sigmoid激活函数和平均汇聚层。请注意，虽然ReLU和最大汇聚层更有效，但它们在20世纪90年代还没有出现。\n",
    "* 每个卷积层使用$5\\times 5$卷积核和一个sigmoid激活函数。\n",
    "* 第一卷积层有6个输出通道，而第二个卷积层有16个输出通道。\n",
    "* 每个$2\\times2$池操作（步幅2）通过空间下采样将维数减少4倍。\n",
    "* 为了将卷积块的输出传递给稠密块，我们必须在小批量中展平每个样本。换言之，我们将这个四维输入转换成全连接层所期望的二维输入。这里的二维表示的第一个维度索引小批量中的样本，第二个维度给出每个样本的平面向量表示。\n",
    "* LeNet的稠密块有三个全连接层，分别有120、84和10个输出。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1543c342",
   "metadata": {},
   "source": [
    "下面，我们将一个大小为$28 \\times 28$的单通道（黑白）图像通过LeNet。\n",
    "![LeNet 的简化版。](./lenet-vert.svg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "74e98ebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ac406967",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN_Model(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN_Model, self).__init__()\n",
    "        self.conv1 = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(1, 6, kernel_size=5, padding=2),\n",
    "            \n",
    "            torch.nn.Sigmoid(),\n",
    "            torch.nn.AvgPool2d(stride=2,kernel_size=2))\n",
    "        \n",
    "        self.conv2=torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(6, 16, kernel_size=5),\n",
    "            \n",
    "            torch.nn.Sigmoid(),\n",
    "            torch.nn.AvgPool2d(stride=2, kernel_size=2))\n",
    "        \n",
    "        self.dense = torch.nn.Sequential(\n",
    "            torch.nn.Flatten(),\n",
    "            torch.nn.Linear(16 * 5 * 5, 120),\n",
    "            torch.nn.Sigmoid(),\n",
    "            \n",
    "            torch.nn.Linear(120, 84),\n",
    "            torch.nn.Sigmoid(),\n",
    "            torch.nn.Linear(84, 10))\n",
    "        \n",
    "    # 前向传播\n",
    "    def forward(self, x):\n",
    "        x1 = self.conv1(x)\n",
    "        x2 = self.conv2(x1)\n",
    "        \n",
    "        x = self.dense(x2)\n",
    "        return x\n",
    "\n",
    "LeNet = CNN_Model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5668624b",
   "metadata": {},
   "source": [
    "## 模型训练"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d9dcdfe",
   "metadata": {},
   "source": [
    " 现在我们已经实现了LeNet，让我们看看[**LeNet在Fashion-MNIST数据集上的表现**]。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "bfa96e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "from torch.utils import data\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9fc6cd5",
   "metadata": {},
   "source": [
    "### 加载数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "1ded1fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "tran = transforms.ToTensor()\n",
    "train_data = torchvision.datasets.FashionMNIST(root='../data', \n",
    "                                               train=True, \n",
    "                                               download=True, \n",
    "                                               transform=tran)\n",
    "test_data = torchvision.datasets.FashionMNIST(root='../data', \n",
    "                                               train=False, \n",
    "                                               download=True, \n",
    "                                               transform=tran)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "39b0b603",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "train_iter = data.DataLoader(train_data, shuffle=True, batch_size=batch_size)\n",
    "test_iter = data.DataLoader(test_data, shuffle=False, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e8df41b",
   "metadata": {},
   "source": [
    "### 定义损失函数和优化器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c60ce00d",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(LeNet.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "bb70f220",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CNN_Model(\n",
       "  (conv1): Sequential(\n",
       "    (0): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "    (1): Sigmoid()\n",
       "    (2): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "  )\n",
       "  (conv2): Sequential(\n",
       "    (0): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
       "    (1): Sigmoid()\n",
       "    (2): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "  )\n",
       "  (dense): Sequential(\n",
       "    (0): Flatten(start_dim=1, end_dim=-1)\n",
       "    (1): Linear(in_features=400, out_features=120, bias=True)\n",
       "    (2): Sigmoid()\n",
       "    (3): Linear(in_features=120, out_features=84, bias=True)\n",
       "    (4): Sigmoid()\n",
       "    (5): Linear(in_features=84, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "LeNet.to(device)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be7544a8",
   "metadata": {},
   "source": [
    "### 训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "af997135",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy in epoch 1: 0.3319000005722046\n",
      "accuracy in epoch 2: 0.6690166592597961\n",
      "accuracy in epoch 3: 0.7191666960716248\n",
      "accuracy in epoch 4: 0.7425333261489868\n",
      "accuracy in epoch 5: 0.759933352470398\n",
      "accuracy in epoch 6: 0.7781333327293396\n",
      "accuracy in epoch 7: 0.7932666540145874\n",
      "accuracy in epoch 8: 0.805150032043457\n",
      "accuracy in epoch 9: 0.816349983215332\n",
      "accuracy in epoch 10: 0.8274500370025635\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    correct = 0\n",
    "    for X, y in train_iter:\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        y_hat = LeNet(X)\n",
    "        l = loss(y_hat, y)  # 计算的是这个batch中所有样本的平均交叉熵损失\n",
    "        l.backward()\n",
    "        optimizer.step()\n",
    "        # _,  pred = torch.max(y_hat.data, 1)\n",
    "        # correct += torch.sum(pred == y)\n",
    "        correct += (torch.argmax(y_hat, axis=1) == y).sum()\n",
    "    print(f'accuracy in epoch {epoch + 1}: {correct / len(train_data)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88c5b825",
   "metadata": {},
   "source": [
    "## 模型测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "0c60f050",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on testing data: 0.8131999969482422\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    correct = 0 \n",
    "    for X, y in test_iter:\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        y_hat =  LeNet(X)\n",
    "        correct += (torch.argmax(y_hat, axis=1) == y).sum()\n",
    "    accuracy = correct / len(test_data)\n",
    "    print(f'Accuracy on testing data: {accuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e97f6a4b",
   "metadata": {},
   "source": [
    "## 模型保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "11a84ca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(LeNet.state_dict(), 'saved_lenet')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c0bbe27",
   "metadata": {},
   "source": [
    "## 模型加载"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "982fb32b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "copy_lenet = CNN_Model().to(device)\n",
    "copy_lenet.load_state_dict(torch.load('saved_lenet'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "2879f2a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on testing data: 0.8131999969482422\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    correct = 0 \n",
    "    for X, y in test_iter:\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        y_hat =  copy_lenet(X)\n",
    "        correct += (torch.argmax(y_hat, axis=1) == y).sum()\n",
    "    accuracy = correct / len(test_data)\n",
    "    print(f'Accuracy on testing data: {accuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0ebca6f",
   "metadata": {},
   "source": [
    "加载的模型与保存的模型在测试集上的预测准确度相同，说明模型的保存和加载是正确的。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ca44dec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
