{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e08defb9",
   "metadata": {},
   "source": [
    "# 图像卷积\n",
    "## 互相关运算\n",
    "`corr2d`函数实现了二维卷积操作（即互相关运算），该函数接受输入张量`X`和卷积核张量`K`，并返回输出张量`Y`。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cc368d47",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c9a49109",
   "metadata": {},
   "outputs": [],
   "source": [
    "def corr2d(X, K):\n",
    "    h, w = K.shape\n",
    "    Y = torch.zeros((X.shape[0] - h + 1, X.shape[1] - w +1))\n",
    "    for i in range(Y.shape[0]):\n",
    "        for j in range(Y.shape[1]):\n",
    "            Y[i, j] = (X[i:i+h, j:j+w] * K).sum()\n",
    "    return Y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15e612c3",
   "metadata": {},
   "source": [
    "我们来[**验证上述二维互相关运算的输出**]。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "280b7558",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0., 1., 2.],\n",
       "         [3., 4., 5.],\n",
       "         [6., 7., 8.]]),\n",
       " tensor([[0., 1.],\n",
       "         [2., 3.]]),\n",
       " tensor([[19., 25.],\n",
       "         [37., 43.]]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.tensor([[0.0, 1.0, 2.0], [3.0, 4.0, 5.0], [6.0, 7.0, 8.0]])\n",
    "K = torch.tensor([[0.0, 1.0], [2.0, 3.0]])\n",
    "X, K, corr2d(X, K)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50c5668d",
   "metadata": {},
   "source": [
    "## 卷积层\n",
    "卷积层对输入和卷积核进行互相关运算，并添加偏置，产生输出。所以，卷积层中需要被训练的参数为卷积核权重和标量偏置。就像我们之前随机初始化全连接层一样，在训练基于卷积层的模型时，我们也随机初始化卷积核权重。\n",
    "\n",
    "基于上面定义的`corr2d`函数[**实现二维卷积层**]。在`__init__`构造函数中，将`weight`和`bias`声明为两个模型参数。前向传播函数调用`corr2d`函数并添加偏置。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bb5e520b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv2D(nn.Module):\n",
    "    def __init__(self, kernel_size):\n",
    "        super().__init__()\n",
    "        self.weight = nn.Parameter(torch.rand(kernel_size))\n",
    "        self.bias = nn.Parameter(torch.zeros(1))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return corr2d(x, self.weight) + self.bias"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcf89a80",
   "metadata": {},
   "source": [
    " ## 卷积的一个应用：图像边缘检测\n",
    " 如下是[**卷积层的一个简单应用：**]通过找到像素变化的位置，来(**检测图像中不同颜色的边缘**)。\n",
    "首先，我们构造一个$6\\times 8$像素的黑白图像。中间四列为黑色（$0$），其余像素为白色（$1$）。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1d4e1a1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 0., 0., 0., 0., 1., 1.],\n",
       "        [1., 1., 0., 0., 0., 0., 1., 1.],\n",
       "        [1., 1., 0., 0., 0., 0., 1., 1.],\n",
       "        [1., 1., 0., 0., 0., 0., 1., 1.],\n",
       "        [1., 1., 0., 0., 0., 0., 1., 1.],\n",
       "        [1., 1., 0., 0., 0., 0., 1., 1.]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.ones(6, 8)\n",
    "X[:, 2:6] = 0\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d02114a",
   "metadata": {},
   "source": [
    "接下来，我们构造一个高度为$1$、宽度为$2$的卷积核`K`。当进行互相关运算时，如果水平相邻的两元素相同，则输出为零，否则输出为非零。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2f6ca067",
   "metadata": {},
   "outputs": [],
   "source": [
    "K = torch.tensor([[1, -1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f591859",
   "metadata": {},
   "source": [
    "现在，我们对参数`X`（输入）和`K`（卷积核）执行互相关运算。\n",
    "如下所示，[**输出`Y`中的1代表从白色到黑色的边缘，-1代表从黑色到白色的边缘**]，其他情况的输出为$0$。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cc0987a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = corr2d(X, K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2c0efb0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.,  1.,  0.,  0.,  0., -1.,  0.],\n",
       "        [ 0.,  1.,  0.,  0.,  0., -1.,  0.],\n",
       "        [ 0.,  1.,  0.,  0.,  0., -1.,  0.],\n",
       "        [ 0.,  1.,  0.,  0.,  0., -1.,  0.],\n",
       "        [ 0.,  1.,  0.,  0.,  0., -1.,  0.],\n",
       "        [ 0.,  1.,  0.,  0.,  0., -1.,  0.]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccd9b3bf",
   "metadata": {},
   "source": [
    "**该卷积核只能检测垂直边缘，不能检测水平边缘**，若我们将X进行转置，在用K对其进行卷积，会发现并不能检测出边缘。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a6c294b",
   "metadata": {},
   "source": [
    "## 学习卷积核\n",
    "如果我们只需寻找黑白边缘，那么以上`[1, -1]`的边缘检测器足以。然而，当有了更复杂数值的卷积核，或者连续的卷积层时，我们不可能手动设计滤波器。那么我们是否可以[**学习由`X`生成`Y`的卷积核**]呢？\n",
    "\n",
    "现在让我们看看是否可以通过仅查看“输入-输出”对来学习由`X`生成`Y`的卷积核。\n",
    "我们先构造一个卷积层，并将其卷积核初始化为随机张量。接下来，在每次迭代中，我们比较`Y`与卷积层输出的平方误差，然后计算梯度来更新卷积核。为了简单起见，我们在此使用内置的二维卷积层，并忽略偏置。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "350a6f62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2, loss 12.303\n",
      "epoch 4, loss 3.974\n",
      "epoch 6, loss 1.449\n",
      "epoch 8, loss 0.564\n",
      "epoch 10, loss 0.226\n"
     ]
    }
   ],
   "source": [
    "# 构造一个二维卷积层，它具有一个输入通道、一个输出通道和一个形状为（1,2）的卷积核\n",
    "conv2d = nn.Conv2d(1, 1, kernel_size=(1, 2), bias=False)\n",
    "\n",
    "# 这个二维卷积层使用四维输入和输出格式（批量大小、通道、高度、宽度），\n",
    "# 其中批量大小和通道数都为1\n",
    "X = X.reshape(1, 1, 6, 8)\n",
    "Y = Y.reshape(1, 1, 6, 7)\n",
    "lr = 3e-2\n",
    "num_epochs = 10\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    Y_hat = conv2d(X)\n",
    "    l = (Y_hat - Y) ** 2\n",
    "    conv2d.zero_grad()\n",
    "    l.sum().backward()\n",
    "    \n",
    "    conv2d.weight.data[:] -= lr * conv2d.weight.grad\n",
    "    if (epoch + 1) % 2 == 0:\n",
    "        print(f'epoch {epoch + 1}, loss {l.sum():.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "eda8eecc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 0.9404, -1.0378]]]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv2d.weight.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6ef0b949",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 0.1217,  1.0438,  0.0000,  0.0000,  0.0000, -0.9221,  0.1217],\n",
       "          [ 0.1217,  1.0438,  0.0000,  0.0000,  0.0000, -0.9221,  0.1217],\n",
       "          [ 0.1217,  1.0438,  0.0000,  0.0000,  0.0000, -0.9221,  0.1217],\n",
       "          [ 0.1217,  1.0438,  0.0000,  0.0000,  0.0000, -0.9221,  0.1217],\n",
       "          [ 0.1217,  1.0438,  0.0000,  0.0000,  0.0000, -0.9221,  0.1217],\n",
       "          [ 0.1217,  1.0438,  0.0000,  0.0000,  0.0000, -0.9221,  0.1217]]]],\n",
       "       grad_fn=<ConvolutionBackward0>)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_hat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83923492",
   "metadata": {},
   "source": [
    "可以看出，经过10次迭代后，卷积核和边缘检测器的误差已经很小。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "223116a8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
